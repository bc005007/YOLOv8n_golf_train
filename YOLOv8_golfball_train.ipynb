{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/ultralytics\n",
    "# !pip install ultralytics\n",
    "# cd ultralytics\n",
    "# !pip install -r requirements.txt\n",
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOLOv8n 모델 다시 다운로드\n",
    "# !wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_summary())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.5.1+cu124\n",
      "CUDA 가능 여부: True\n",
      "현재 사용 중인 CUDA 버전: 12.4\n",
      "CUDNN 버전: 90100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"현재 사용 중인 CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"CUDNN 버전: {torch.backends.cudnn.version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 12 06:54:10 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:C1:00.0 Off |                  Off |\n",
      "|  0%   45C    P8             24W /  450W |       4MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True가 출력되어야 GPU 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라벨링 데이터가 골프공 하나일때만 돌리기!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨링 번호가 모두 0로 변경되었습니다.\n",
      "라벨링 번호가 모두 0로 변경되었습니다.\n",
      "라벨링 번호가 모두 0로 변경되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = ['train', 'valid', 'test']\n",
    "\n",
    "def change_class_number(label_dir, new_class_number):\n",
    "    # 디렉토리 내 모든 .txt 파일을 순회\n",
    "    label_dir = f'./merged_golfball/{label_dir}/labels'\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith('.txt'):\n",
    "            label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "            # 라벨 파일 읽기\n",
    "            with open(label_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # 각 줄의 클래스 번호를 new_class_number로 변경\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) > 0:\n",
    "                    parts[0] = str(new_class_number)  # 클래스 번호를 new_class_number로 변경\n",
    "                    new_lines.append(' '.join(parts))\n",
    "\n",
    "            # 수정된 내용을 다시 라벨 파일에 쓰기\n",
    "            with open(label_path, 'w') as file:\n",
    "                file.write('\\n'.join(new_lines) + '\\n')\n",
    "\n",
    "    print(f\"라벨링 번호가 모두 {new_class_number}로 변경되었습니다.\")\n",
    "\n",
    "for label_dir in dir:\n",
    "    change_class_number(label_dir, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 학습 실험 하시려면 여기만 건들이세요!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "New https://pypi.org/project/ultralytics/8.3.29 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.27 🚀 Python-3.9.20 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24111MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./merged_golfball/data.yaml, epochs=100, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_golf_ball_merged_data_100epoch_8batch_10patience, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 26.5MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 15.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/YOLOv8n_Golfball/merged_golfball/train/labels... 4381 images, 7 backgrounds, 0 corrupt: 100%|██████████| 4381/4381 [00:04<00:00, 923.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/YOLOv8n_Golfball/merged_golfball/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/YOLOv8n_Golfball/merged_golfball/valid/labels... 448 images, 1 backgrounds, 0 corrupt: 100%|██████████| 448/448 [00:00<00:00, 972.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/YOLOv8n_Golfball/merged_golfball/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.28G     0.9819       1.33      1.178          4        640: 100%|██████████| 548/548 [00:34<00:00, 15.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.855      0.808      0.843      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      1.26G       1.02     0.9609      1.196         20        640: 100%|██████████| 548/548 [00:33<00:00, 16.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.901        0.8      0.874      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      1.27G     0.9944     0.8596      1.189          6        640: 100%|██████████| 548/548 [00:29<00:00, 18.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.92      0.804      0.856       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      1.25G     0.9666     0.8246      1.175         15        640: 100%|██████████| 548/548 [00:32<00:00, 17.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.86      0.844      0.878      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      1.25G     0.9391     0.7497      1.151         16        640: 100%|██████████| 548/548 [00:29<00:00, 18.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.931      0.832      0.902      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      1.26G     0.9284     0.7183       1.15         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.914       0.86      0.898      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100       1.3G      0.911     0.6965       1.15         12        640: 100%|██████████| 548/548 [00:28<00:00, 18.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.944      0.844      0.908      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      1.25G     0.8849     0.6701      1.126         17        640: 100%|██████████| 548/548 [00:29<00:00, 18.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.916      0.869      0.911      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      1.28G     0.8805     0.6626      1.125         12        640: 100%|██████████| 548/548 [00:29<00:00, 18.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.912       0.88      0.913      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      1.43G     0.8565     0.6234       1.11          9        640: 100%|██████████| 548/548 [00:29<00:00, 18.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.921      0.875      0.927      0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      1.26G     0.8568     0.6189      1.107         17        640: 100%|██████████| 548/548 [00:28<00:00, 18.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.916      0.829      0.896      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      1.32G     0.8323     0.6052      1.099         14        640: 100%|██████████| 548/548 [00:29<00:00, 18.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.855      0.924      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      1.28G      0.828      0.588      1.097         12        640: 100%|██████████| 548/548 [00:28<00:00, 19.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.929       0.86      0.915      0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      1.24G     0.8358     0.5875      1.101         12        640: 100%|██████████| 548/548 [00:28<00:00, 18.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943       0.86      0.932      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      1.25G     0.8283     0.5833      1.098         21        640: 100%|██████████| 548/548 [00:28<00:00, 18.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.931      0.871      0.923      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      1.35G     0.8159     0.5583      1.088         14        640: 100%|██████████| 548/548 [00:28<00:00, 19.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.904      0.893      0.929      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      1.25G     0.8001     0.5572      1.077         28        640: 100%|██████████| 548/548 [00:28<00:00, 19.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.873      0.923       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      1.24G     0.8035     0.5442      1.086         12        640: 100%|██████████| 548/548 [00:29<00:00, 18.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.937      0.872      0.929      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      1.24G     0.7928      0.533      1.079         15        640: 100%|██████████| 548/548 [00:29<00:00, 18.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.923       0.86      0.916      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      1.33G     0.7884     0.5281       1.07         27        640: 100%|██████████| 548/548 [00:29<00:00, 18.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 17.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.896      0.912      0.925      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.34G     0.7855     0.5335      1.077          5        640: 100%|██████████| 548/548 [00:30<00:00, 17.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.919      0.855      0.924      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.24G      0.773      0.517      1.069         10        640: 100%|██████████| 548/548 [00:31<00:00, 17.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.928      0.891       0.94      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      1.25G     0.7732     0.5128      1.066         13        640: 100%|██████████| 548/548 [00:30<00:00, 18.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.963      0.871      0.942      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.23G      0.764     0.5012      1.059         16        640: 100%|██████████| 548/548 [00:28<00:00, 19.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.915       0.89      0.918      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.31G     0.7684     0.5077      1.058         17        640: 100%|██████████| 548/548 [00:30<00:00, 17.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.936      0.887      0.952      0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      1.24G     0.7559     0.4965      1.059         18        640: 100%|██████████| 548/548 [00:29<00:00, 18.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.924      0.888      0.937       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      1.32G     0.7574     0.4849      1.055         12        640: 100%|██████████| 548/548 [00:29<00:00, 18.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.951      0.871      0.941      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.34G     0.7444     0.4782      1.051         15        640: 100%|██████████| 548/548 [00:29<00:00, 18.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.915      0.881      0.945      0.747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.25G     0.7423     0.4819      1.052         13        640: 100%|██████████| 548/548 [00:28<00:00, 18.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.91      0.896       0.94       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100       1.3G     0.7482     0.4734      1.051         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.942      0.863      0.944      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      1.24G     0.7387     0.4741      1.045          6        640: 100%|██████████| 548/548 [00:29<00:00, 18.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.894      0.924      0.948      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100       1.3G     0.7331     0.4645      1.038          9        640: 100%|██████████| 548/548 [00:29<00:00, 18.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.916      0.916      0.949      0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.19G     0.7266     0.4658       1.04         29        640: 100%|██████████| 548/548 [00:28<00:00, 18.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.902      0.916      0.948       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      1.28G     0.7188     0.4606      1.035          8        640: 100%|██████████| 548/548 [00:28<00:00, 18.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.937       0.91      0.956      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.29G     0.7139     0.4483      1.031         17        640: 100%|██████████| 548/548 [00:28<00:00, 19.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.933      0.902      0.944      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.25G     0.7185     0.4455      1.036          9        640: 100%|██████████| 548/548 [00:28<00:00, 19.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715        0.9      0.905      0.948      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.24G     0.7063     0.4394      1.029         31        640: 100%|██████████| 548/548 [00:28<00:00, 19.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.929      0.902       0.96      0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      1.34G     0.7052     0.4356      1.029         21        640: 100%|██████████| 548/548 [00:28<00:00, 19.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.903      0.902      0.944      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      1.25G     0.7087     0.4395      1.031         15        640: 100%|██████████| 548/548 [00:28<00:00, 19.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.916      0.903      0.947       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      1.24G     0.7079      0.437      1.023          8        640: 100%|██████████| 548/548 [00:28<00:00, 18.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943       0.91      0.951      0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      1.27G     0.6891     0.4256      1.019         19        640: 100%|██████████| 548/548 [00:28<00:00, 18.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.949      0.916      0.963      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      1.35G     0.6979     0.4301      1.021         29        640: 100%|██████████| 548/548 [00:29<00:00, 18.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.949      0.878       0.94      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      1.19G     0.6873     0.4247      1.014          7        640: 100%|██████████| 548/548 [00:28<00:00, 19.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.929        0.9       0.95      0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      1.38G     0.6804     0.4239      1.015          5        640: 100%|██████████| 548/548 [00:29<00:00, 18.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.936      0.903      0.953      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      1.18G     0.6814     0.4157      1.014         12        640: 100%|██████████| 548/548 [00:28<00:00, 19.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.938      0.899      0.953      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100       1.3G     0.6715     0.4129      1.012          6        640: 100%|██████████| 548/548 [00:28<00:00, 19.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.929      0.908      0.944      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      1.25G     0.6753     0.4114      1.012          9        640: 100%|██████████| 548/548 [00:29<00:00, 18.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.923      0.908      0.945      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      1.35G     0.6718     0.4092      1.009         13        640: 100%|██████████| 548/548 [00:28<00:00, 18.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.898      0.952      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      1.31G      0.665     0.4077      1.007         17        640: 100%|██████████| 548/548 [00:29<00:00, 18.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.939      0.889      0.951      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      1.25G     0.6519     0.3929      1.003          6        640: 100%|██████████| 548/548 [00:28<00:00, 19.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.94      0.914      0.959      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      1.36G     0.6643     0.4056      1.003         23        640: 100%|██████████| 548/548 [00:28<00:00, 19.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.927      0.899       0.95      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      1.25G     0.6543     0.3876     0.9993          8        640: 100%|██████████| 548/548 [00:28<00:00, 19.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.946      0.898      0.951      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      1.25G     0.6479     0.3911      1.002         12        640: 100%|██████████| 548/548 [00:28<00:00, 19.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.945      0.908       0.95       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      1.29G     0.6448     0.3902     0.9977         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.928      0.913      0.959      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      1.29G     0.6427     0.3886     0.9925         11        640: 100%|██████████| 548/548 [00:29<00:00, 18.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.933      0.905      0.952      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      1.29G     0.6352      0.383     0.9961         16        640: 100%|██████████| 548/548 [00:28<00:00, 19.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.916      0.931      0.948      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      1.29G     0.6343     0.3802     0.9918          8        640: 100%|██████████| 548/548 [00:29<00:00, 18.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.93      0.902      0.947      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100       1.3G     0.6316     0.3782     0.9908         12        640: 100%|██████████| 548/548 [00:28<00:00, 19.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.873      0.943      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      1.25G     0.6295     0.3806     0.9881         21        640: 100%|██████████| 548/548 [00:29<00:00, 18.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.938      0.906      0.946      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      1.33G     0.6261     0.3779     0.9862         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.935      0.888      0.945      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      1.28G     0.6268      0.379      0.991         14        640: 100%|██████████| 548/548 [00:28<00:00, 18.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.961      0.888      0.953      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      1.29G     0.6219     0.3724     0.9876         12        640: 100%|██████████| 548/548 [00:29<00:00, 18.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.937      0.902       0.95      0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      1.28G     0.6103     0.3653      0.985         17        640: 100%|██████████| 548/548 [00:29<00:00, 18.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.961        0.9       0.95      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      1.32G     0.6197     0.3723     0.9798         16        640: 100%|██████████| 548/548 [00:29<00:00, 18.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.917      0.915      0.949      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      1.24G     0.6098     0.3617     0.9818         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.926       0.93      0.953      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      1.25G     0.6071     0.3631     0.9793         19        640: 100%|██████████| 548/548 [00:29<00:00, 18.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.944      0.905      0.963       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      1.22G     0.6017     0.3556     0.9793          8        640: 100%|██████████| 548/548 [00:29<00:00, 18.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.954      0.926      0.962      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      1.27G     0.5978     0.3556     0.9692         11        640: 100%|██████████| 548/548 [00:29<00:00, 18.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.945      0.927      0.966      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      1.34G     0.5939      0.354     0.9735         12        640: 100%|██████████| 548/548 [00:29<00:00, 18.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.952      0.908      0.966      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      1.25G     0.5904      0.351     0.9707         14        640: 100%|██████████| 548/548 [00:29<00:00, 18.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.958      0.902       0.96      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      1.22G     0.5875     0.3515     0.9704          8        640: 100%|██████████| 548/548 [00:28<00:00, 19.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.95      0.905      0.957      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      1.31G      0.576     0.3403     0.9638         18        640: 100%|██████████| 548/548 [00:27<00:00, 19.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.941      0.915      0.959      0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100       1.3G     0.5855     0.3477     0.9715         11        640: 100%|██████████| 548/548 [00:27<00:00, 19.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.92      0.921      0.951      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      1.29G     0.5789     0.3398     0.9635          8        640: 100%|██████████| 548/548 [00:28<00:00, 19.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.957      0.898      0.963      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100       1.3G     0.5758     0.3382     0.9645          8        640: 100%|██████████| 548/548 [00:28<00:00, 19.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.961      0.905      0.955       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      1.38G     0.5687     0.3406     0.9636          8        640: 100%|██████████| 548/548 [00:29<00:00, 18.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.94      0.916       0.96      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      1.25G     0.5638     0.3325     0.9627         27        640: 100%|██████████| 548/548 [00:29<00:00, 18.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.947      0.907       0.96      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      1.29G      0.562     0.3273     0.9588         13        640: 100%|██████████| 548/548 [00:28<00:00, 19.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.947      0.922      0.959      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      1.39G     0.5623     0.3348     0.9583          8        640: 100%|██████████| 548/548 [00:28<00:00, 19.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.935      0.916      0.963      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      1.28G     0.5622     0.3297     0.9587         11        640: 100%|██████████| 548/548 [00:29<00:00, 18.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.917       0.96      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      1.25G     0.5589     0.3323     0.9546         13        640: 100%|██████████| 548/548 [00:29<00:00, 18.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.946      0.911      0.956      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      1.25G     0.5499     0.3229     0.9555         14        640: 100%|██████████| 548/548 [00:28<00:00, 19.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.959      0.908      0.957      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100       1.3G      0.544     0.3205     0.9493          7        640: 100%|██████████| 548/548 [00:28<00:00, 19.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.943      0.918      0.965      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      1.19G     0.5444      0.324     0.9547          9        640: 100%|██████████| 548/548 [00:29<00:00, 18.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.95      0.913      0.968      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      1.19G     0.5394     0.3141     0.9523          9        640: 100%|██████████| 548/548 [00:29<00:00, 18.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.945      0.915      0.957       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      1.25G     0.5377     0.3143     0.9483         11        640: 100%|██████████| 548/548 [00:29<00:00, 18.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.957      0.913      0.952      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      1.25G     0.5407      0.319     0.9483         18        640: 100%|██████████| 548/548 [00:28<00:00, 19.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:01<00:00, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.964      0.903      0.959      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 77, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "87 epochs completed in 0.753 hours.\n",
      "Optimizer stripped from runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience/weights/best.pt...\n",
      "Ultralytics 8.3.27 🚀 Python-3.9.20 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24111MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:02<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715       0.93      0.922      0.959      0.782\n",
      "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f0d541fa2b0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99743,     0.99743,      0.9949,      0.9949,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,\n",
       "            0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.99307,     0.98967,     0.98967,     0.98967,     0.98799,\n",
       "            0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,     0.98671,\n",
       "            0.98671,     0.98671,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.98055,     0.97271,     0.96232,     0.96232,     0.96232,     0.96232,\n",
       "            0.96232,     0.96232,     0.96232,     0.96232,     0.96232,     0.96232,     0.95956,     0.95956,     0.95956,     0.95956,     0.95956,     0.95956,     0.95699,     0.95699,     0.95699,     0.95699,     0.95699,     0.95699,     0.95699,     0.95699,     0.95559,      0.9542,      0.9542,\n",
       "            0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.95202,     0.94955,     0.94955,     0.94955,     0.94955,     0.94955,     0.94955,     0.94955,     0.94682,     0.93886,\n",
       "            0.93886,     0.93886,     0.93886,     0.93886,     0.93886,       0.934,       0.934,       0.934,       0.934,       0.934,       0.934,       0.934,       0.934,     0.93276,     0.93211,     0.93211,     0.93211,     0.93211,     0.93211,     0.93211,     0.93211,     0.93211,     0.93211,\n",
       "            0.93211,     0.92577,     0.92577,     0.92577,      0.9234,      0.9234,      0.9234,     0.92222,     0.92127,     0.92127,     0.92127,     0.92127,     0.91293,     0.91293,     0.91293,     0.91293,     0.91293,     0.91293,     0.90934,     0.90823,     0.90823,     0.87891,     0.87891,\n",
       "            0.87891,     0.87018,     0.87018,     0.86718,     0.86718,     0.86718,     0.83436,     0.83436,     0.83049,     0.82767,     0.81504,     0.81504,     0.75748,     0.75691,     0.75691,      0.7293,      0.7293,     0.69848,     0.69848,     0.69737,      0.5274,      0.5274,      0.5274,\n",
       "             0.5274,      0.5274,      0.5274,     0.37473,     0.37206,     0.37206,     0.37179,     0.37173,     0.30335,     0.30335,     0.30286,     0.21991,     0.20992,     0.19992,     0.18993,     0.17993,     0.16993,     0.15994,     0.14994,     0.13995,     0.12995,     0.11995,     0.10996,\n",
       "           0.099961,    0.089965,    0.079969,    0.069973,    0.059977,    0.049981,    0.039984,    0.029988,    0.019992,   0.0099961,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.36378,     0.36378,     0.46793,     0.52622,     0.56043,     0.58934,     0.60685,      0.6212,     0.64053,     0.65368,     0.66571,     0.67496,      0.6826,     0.68554,     0.69581,     0.70486,     0.70954,     0.71618,     0.72051,     0.72406,     0.72649,     0.72915,     0.73193,\n",
       "            0.73459,     0.73716,     0.73827,     0.74041,     0.74098,     0.74344,     0.74562,     0.74968,     0.75199,     0.75477,     0.75733,     0.76399,     0.76789,     0.77124,     0.77369,     0.77649,     0.77874,     0.77999,     0.78332,     0.78427,      0.7861,     0.78934,     0.79039,\n",
       "            0.79186,     0.79489,     0.79772,     0.79912,     0.80087,      0.8016,      0.8028,     0.80361,     0.80482,     0.80573,      0.8087,     0.80908,      0.8088,      0.8088,     0.80889,     0.80898,     0.80908,     0.80917,     0.80975,        0.81,     0.81154,     0.81493,     0.81545,\n",
       "            0.81704,     0.81765,     0.81941,     0.82028,     0.82235,     0.82365,     0.82505,     0.82678,     0.82817,     0.82849,     0.82794,      0.8283,     0.83055,     0.83114,     0.83154,      0.8321,     0.83359,      0.8346,     0.83505,     0.83542,     0.83572,     0.83613,      0.8375,\n",
       "            0.83792,       0.838,     0.83807,     0.83814,     0.83821,     0.83829,     0.83836,     0.83843,     0.83904,     0.83933,     0.84023,      0.8408,     0.84159,     0.84179,       0.842,     0.84316,     0.84336,     0.84356,     0.84395,     0.84433,     0.84467,     0.84493,      0.8452,\n",
       "            0.84546,     0.84554,     0.84528,     0.84494,     0.84624,     0.84807,     0.84941,     0.85055,     0.85187,     0.85378,     0.85386,     0.85394,     0.85402,      0.8541,     0.85418,     0.85426,     0.85442,     0.85464,     0.85493,     0.85594,     0.85619,     0.85646,      0.8579,\n",
       "            0.85832,     0.85883,      0.8603,     0.86071,     0.86125,     0.86204,     0.86226,     0.86246,     0.86263,      0.8628,     0.86296,     0.86307,     0.86318,      0.8633,     0.86341,     0.86403,     0.86426,      0.8645,      0.8648,     0.86515,     0.86615,     0.86674,     0.86779,\n",
       "            0.87011,     0.87022,     0.87034,     0.87045,     0.87056,     0.87119,     0.87169,     0.87269,     0.87302,     0.87322,     0.87354,     0.87403,     0.87415,     0.87428,      0.8744,     0.87452,     0.87457,     0.87462,     0.87467,     0.87471,     0.87476,     0.87481,     0.87486,\n",
       "            0.87491,     0.87496,       0.875,     0.87505,     0.87514,     0.87528,     0.87541,     0.87555,     0.87578,     0.87679,      0.8771,     0.87756,      0.8786,     0.87882,     0.87956,     0.87916,     0.87966,     0.88037,     0.88116,     0.88123,     0.88129,     0.88135,     0.88142,\n",
       "            0.88148,     0.88154,     0.88161,     0.88167,     0.88208,     0.88251,      0.8828,      0.8836,      0.8841,     0.88433,     0.88455,     0.88496,     0.88588,     0.88616,     0.88568,     0.88572,     0.88589,     0.88606,     0.88618,     0.88625,     0.88632,     0.88638,     0.88645,\n",
       "            0.88652,     0.88659,     0.88666,     0.88677,     0.88705,     0.88727,     0.88707,     0.88686,     0.88665,     0.88762,     0.88842,     0.88837,     0.88992,     0.89012,     0.89032,     0.89053,     0.89079,     0.89106,     0.89126,     0.89146,     0.89166,     0.89193,      0.8922,\n",
       "            0.89238,     0.89254,      0.8927,     0.89285,     0.89299,     0.89312,     0.89326,     0.89339,     0.89427,      0.8946,     0.89466,     0.89472,     0.89478,     0.89484,      0.8949,     0.89496,     0.89502,     0.89509,     0.89515,     0.89581,     0.89592,     0.89602,     0.89613,\n",
       "            0.89623,     0.89634,     0.89693,      0.8976,     0.89765,      0.8977,     0.89775,      0.8978,     0.89785,      0.8979,     0.89795,       0.898,     0.89805,      0.8981,     0.89875,     0.89956,     0.90012,     0.90047,     0.90133,     0.90158,     0.90205,     0.90287,     0.90369,\n",
       "            0.90387,     0.90404,     0.90456,     0.90487,     0.90505,     0.90522,     0.90543,     0.90567,     0.90592,     0.90638,      0.9062,     0.90603,     0.90585,     0.90509,     0.90532,     0.90554,     0.90635,     0.90649,     0.90664,     0.90679,     0.90673,     0.90606,     0.90563,\n",
       "            0.90557,     0.90582,     0.90605,     0.90617,     0.90629,     0.90641,     0.90653,     0.90665,     0.90726,     0.90738,      0.9075,     0.90762,     0.90774,     0.90785,     0.90842,     0.90871,     0.90896,     0.90924,     0.90955,     0.90989,     0.91025,     0.90914,     0.90947,\n",
       "            0.90961,     0.90975,     0.90989,     0.91003,     0.91074,     0.91082,      0.9109,     0.91097,     0.91105,     0.91113,      0.9112,     0.91128,     0.91146,     0.91169,     0.91192,     0.91206,      0.9122,     0.91234,     0.91249,     0.91259,     0.91268,     0.91276,     0.91285,\n",
       "            0.91293,     0.91302,      0.9131,     0.91323,     0.91346,     0.91369,     0.91453,     0.91474,     0.91495,     0.91527,     0.91563,     0.91569,     0.91574,     0.91579,     0.91584,     0.91589,     0.91593,     0.91598,     0.91603,     0.91608,     0.91613,     0.91617,     0.91622,\n",
       "            0.91629,     0.91756,     0.91816,      0.9184,     0.91863,     0.91966,     0.92093,     0.92139,     0.92163,     0.92186,     0.92241,     0.92306,     0.92329,     0.92343,     0.92357,      0.9237,     0.92387,      0.9242,     0.92428,     0.92388,     0.92428,     0.92402,     0.92377,\n",
       "            0.92433,     0.92456,      0.9248,     0.92532,     0.92499,     0.92423,     0.92375,     0.92337,     0.92318,     0.92305,     0.92292,     0.92279,     0.92265,     0.92258,      0.9228,     0.92302,     0.92319,     0.92322,     0.92325,     0.92329,     0.92332,     0.92335,     0.92338,\n",
       "            0.92341,     0.92344,     0.92348,     0.92351,     0.92354,     0.92357,      0.9236,     0.92363,     0.92367,      0.9237,     0.92373,     0.92376,     0.92379,     0.92383,     0.92415,     0.92447,     0.92465,     0.92482,       0.925,     0.92579,      0.9259,     0.92601,     0.92612,\n",
       "            0.92623,     0.92634,     0.92657,      0.9269,     0.92658,     0.92621,     0.92608,     0.92595,     0.92582,      0.9257,     0.92557,     0.92539,      0.9252,     0.92501,     0.92482,     0.92508,     0.92541,      0.9252,     0.92495,     0.92469,     0.92443,     0.92427,     0.92412,\n",
       "            0.92397,     0.92455,     0.92502,     0.92436,     0.92428,      0.9242,     0.92413,     0.92405,     0.92397,     0.92389,     0.92382,     0.92374,     0.92366,     0.92371,     0.92393,     0.92415,     0.92458,     0.92563,     0.92576,      0.9259,     0.92603,     0.92616,     0.92624,\n",
       "            0.92629,     0.92634,     0.92639,     0.92643,     0.92648,     0.92653,     0.92658,     0.92662,     0.92667,     0.92672,     0.92677,     0.92681,     0.92686,     0.92676,     0.92665,     0.92654,     0.92643,     0.92631,      0.9262,     0.92534,     0.92528,     0.92522,     0.92517,\n",
       "            0.92511,     0.92505,     0.92499,     0.92493,     0.92487,     0.92481,     0.92475,     0.92469,     0.92463,     0.92458,     0.92454,      0.9245,     0.92446,     0.92443,     0.92439,     0.92435,     0.92431,     0.92427,     0.92424,      0.9242,     0.92416,     0.92412,     0.92408,\n",
       "            0.92405,     0.92401,     0.92397,     0.92393,      0.9239,     0.92386,     0.92348,       0.923,     0.92285,     0.92269,     0.92253,     0.92238,     0.92185,     0.92197,      0.9217,     0.92149,     0.92156,     0.92162,     0.92169,     0.92176,     0.92182,     0.92189,     0.92196,\n",
       "            0.92202,     0.92209,     0.92138,     0.92117,     0.92099,     0.92082,     0.92065,     0.91971,     0.91956,      0.9194,     0.91924,     0.91909,     0.91813,     0.91794,     0.91774,     0.91754,     0.91824,     0.91837,     0.91849,     0.91861,     0.91873,     0.91885,     0.91896,\n",
       "            0.91907,     0.91918,      0.9193,     0.91941,      0.9195,     0.91958,     0.91966,     0.91974,     0.91982,      0.9199,     0.91998,     0.92006,     0.91991,     0.91912,     0.91833,     0.91771,     0.91745,     0.91718,     0.91713,      0.9174,     0.91767,     0.91779,      0.9179,\n",
       "            0.91801,     0.91813,     0.91824,     0.91849,     0.91902,     0.91907,     0.91911,     0.91916,      0.9192,     0.91925,     0.91929,     0.91934,     0.91939,     0.91943,     0.91948,     0.91952,     0.91957,     0.91961,     0.91966,     0.92038,     0.92044,      0.9205,     0.92056,\n",
       "            0.92062,     0.92069,     0.92075,     0.92081,     0.92087,     0.92093,     0.92094,     0.92079,     0.92065,     0.92051,     0.92036,     0.92022,     0.92092,     0.92098,     0.92103,     0.92109,     0.92115,     0.92121,     0.92127,     0.92133,     0.92139,     0.92145,     0.92151,\n",
       "            0.92148,      0.9214,     0.92132,     0.92125,     0.92117,      0.9211,     0.92102,     0.92094,     0.92087,     0.92079,     0.91986,     0.91959,     0.91932,     0.91841,     0.91823,     0.91805,     0.91787,      0.9177,     0.91775,     0.91795,     0.91814,     0.91884,     0.91831,\n",
       "            0.91709,     0.91669,     0.91618,     0.91571,     0.91539,     0.91507,     0.91431,     0.91331,     0.91314,     0.91298,     0.91282,     0.91187,     0.91179,     0.91171,     0.91162,     0.91154,     0.91146,     0.91138,      0.9113,     0.91122,     0.91114,     0.91121,     0.91166,\n",
       "            0.91177,     0.91179,     0.91182,     0.91185,     0.91187,      0.9119,     0.91193,     0.91196,     0.91198,     0.91201,     0.91204,     0.91207,     0.91209,     0.91212,     0.91215,     0.91218,      0.9122,     0.91223,     0.91226,     0.91228,     0.91231,     0.91234,     0.91237,\n",
       "            0.91239,     0.91229,     0.91202,     0.91175,     0.91184,     0.91226,     0.91171,     0.91157,     0.91173,     0.91188,     0.91203,       0.912,     0.91124,     0.91069,     0.90935,     0.90884,     0.90843,     0.90805,     0.90772,     0.90739,     0.90858,     0.90839,     0.90806,\n",
       "            0.90775,     0.90748,      0.9072,     0.90625,     0.90621,     0.90617,     0.90613,     0.90609,     0.90605,     0.90601,     0.90597,     0.90593,     0.90589,     0.90585,     0.90581,     0.90577,     0.90573,     0.90569,     0.90564,      0.9056,     0.90556,     0.90552,     0.90548,\n",
       "            0.90585,     0.90617,     0.90623,     0.90629,     0.90635,     0.90641,     0.90647,     0.90653,     0.90659,     0.90665,     0.90671,     0.90677,     0.90621,     0.90527,     0.90369,     0.90334,      0.9031,     0.90286,     0.90268,     0.90254,      0.9024,     0.90226,     0.90212,\n",
       "            0.90198,     0.90157,      0.9025,     0.90273,     0.90296,     0.90417,     0.90551,     0.90575,     0.90552,     0.90528,     0.90504,     0.90563,     0.90612,     0.90669,     0.90718,     0.90746,     0.90774,     0.90809,     0.90756,     0.90722,     0.90688,      0.9064,     0.90578,\n",
       "            0.90508,     0.90489,      0.9047,     0.90452,     0.90433,     0.90383,     0.90037,     0.89941,     0.90042,     0.90152,     0.90187,     0.90191,     0.90163,     0.90134,     0.89869,      0.8985,     0.89831,     0.89812,     0.89793,     0.89728,     0.89606,     0.89548,       0.893,\n",
       "             0.8906,     0.89008,     0.88986,     0.88964,     0.88942,     0.88837,     0.88818,     0.88798,     0.88779,     0.88668,     0.88731,     0.88572,     0.88694,     0.88635,     0.88502,     0.88402,     0.88233,     0.87906,     0.87846,     0.87256,     0.87145,     0.86654,     0.86352,\n",
       "            0.86065,     0.85973,     0.85666,     0.85604,     0.85149,     0.83845,     0.82895,     0.82481,     0.82406,     0.81919,     0.81427,     0.81226,      0.8063,     0.80396,     0.80194,     0.80092,     0.79104,     0.78589,     0.77966,     0.77231,     0.76844,      0.7663,     0.75452,\n",
       "            0.75185,     0.74745,       0.728,     0.71831,      0.7102,     0.70327,      0.6974,     0.68778,     0.68609,     0.67673,     0.66555,     0.65672,     0.64776,     0.62428,      0.6189,     0.60444,      0.5957,     0.58451,      0.5829,     0.57733,     0.57443,     0.57008,     0.55847,\n",
       "             0.5511,     0.54216,     0.52403,     0.51722,     0.50066,     0.48734,     0.46838,     0.44329,     0.42086,     0.40669,     0.38865,     0.38089,     0.36451,     0.33973,     0.30016,     0.28167,     0.25855,     0.19696,     0.17847,     0.17019,     0.16544,     0.14021,      0.1328,\n",
       "            0.12287,    0.098196,    0.096466,    0.082664,    0.077786,    0.076903,    0.076019,    0.071353,     0.06076,    0.049582,    0.034773,    0.030987,    0.029928,      0.0295,    0.029071,    0.028643,    0.028214,    0.027785,    0.021862,     0.01348,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.22347,     0.22347,     0.30785,     0.36038,     0.39418,     0.42339,      0.4417,     0.45707,     0.47831,     0.49314,     0.50695,     0.51776,     0.52681,       0.532,     0.54447,     0.55565,     0.56149,     0.56984,     0.57534,     0.57989,     0.58301,     0.58645,     0.59005,\n",
       "            0.59352,     0.59688,     0.59833,     0.60115,     0.60191,     0.60516,     0.60805,     0.61347,     0.61657,     0.62032,     0.62378,     0.63288,     0.63824,     0.64288,      0.6463,     0.65022,     0.65337,     0.65513,     0.65984,      0.6612,      0.6638,     0.66843,     0.66994,\n",
       "            0.67207,     0.67643,     0.68054,     0.68259,     0.68515,     0.68621,     0.68798,     0.68917,     0.69095,     0.69229,     0.69668,     0.69724,     0.69821,      0.6983,     0.69844,     0.69858,     0.69872,     0.69886,     0.69972,      0.7001,      0.7024,      0.7075,     0.70828,\n",
       "            0.71069,     0.71161,     0.71428,      0.7156,     0.71875,     0.72074,     0.72288,     0.72555,     0.72769,     0.72901,     0.72878,      0.7295,       0.733,     0.73392,     0.73455,     0.73542,     0.73775,     0.73934,     0.74004,     0.74063,      0.7411,     0.74175,      0.7439,\n",
       "            0.74457,     0.74469,      0.7448,     0.74491,     0.74503,     0.74514,     0.74526,     0.74537,     0.74633,     0.74679,     0.74822,     0.74913,     0.75038,     0.75071,     0.75103,     0.75288,     0.75319,     0.75351,     0.75415,     0.75475,     0.75529,     0.75571,     0.75614,\n",
       "            0.75655,     0.75686,      0.7574,     0.75748,     0.75957,     0.76253,     0.76468,     0.76655,     0.76868,      0.7718,     0.77193,     0.77206,     0.77219,     0.77232,     0.77245,     0.77258,     0.77285,     0.77321,     0.77368,     0.77534,     0.77575,     0.77619,     0.77856,\n",
       "            0.77924,     0.78009,     0.78253,     0.78319,     0.78409,      0.7854,     0.78577,      0.7861,     0.78639,     0.78667,     0.78693,     0.78712,     0.78731,      0.7875,     0.78769,     0.78871,     0.78911,      0.7895,        0.79,     0.79059,     0.79226,     0.79324,     0.79501,\n",
       "            0.79891,      0.7991,     0.79929,     0.79948,     0.79967,     0.80073,     0.80158,     0.80327,     0.80382,     0.80418,     0.80471,     0.80554,     0.80575,     0.80596,     0.80617,     0.80638,     0.80646,     0.80654,     0.80662,     0.80671,     0.80679,     0.80687,     0.80695,\n",
       "            0.80704,     0.80712,      0.8072,     0.80728,     0.80743,     0.80766,     0.80789,     0.80812,     0.80852,     0.81024,     0.81077,     0.81156,     0.81334,     0.81372,     0.81503,     0.81491,     0.81619,     0.81741,     0.81877,     0.81888,     0.81899,      0.8191,     0.81921,\n",
       "            0.81932,     0.81943,     0.81954,     0.81965,     0.82035,      0.8211,      0.8216,     0.82298,     0.82386,     0.82425,     0.82464,     0.82536,     0.82695,     0.82744,     0.82749,     0.82773,     0.82802,     0.82832,     0.82853,     0.82865,     0.82877,     0.82889,     0.82901,\n",
       "            0.82914,     0.82926,     0.82938,     0.82957,     0.83006,     0.83048,     0.83042,     0.83036,      0.8303,     0.83212,     0.83423,     0.83452,     0.83726,     0.83761,     0.83796,     0.83833,      0.8388,     0.83928,     0.83964,     0.83999,     0.84035,     0.84082,      0.8413,\n",
       "            0.84162,      0.8419,     0.84219,     0.84247,     0.84271,     0.84294,     0.84318,     0.84342,       0.845,     0.84559,     0.84569,      0.8458,     0.84591,     0.84602,     0.84613,     0.84623,     0.84634,     0.84645,     0.84656,     0.84775,     0.84794,     0.84812,     0.84831,\n",
       "             0.8485,     0.84869,     0.84975,     0.85096,     0.85105,     0.85114,     0.85123,     0.85132,     0.85141,      0.8515,     0.85159,     0.85168,     0.85177,     0.85186,     0.85303,     0.85449,     0.85551,     0.85614,     0.85769,     0.85814,       0.859,     0.86048,     0.86197,\n",
       "             0.8623,     0.86262,     0.86355,     0.86412,     0.86444,     0.86477,     0.86514,     0.86559,     0.86604,     0.86714,      0.8671,     0.86706,     0.86702,     0.86686,     0.86727,     0.86769,     0.86916,     0.86943,      0.8697,     0.86997,     0.87014,     0.86999,     0.86989,\n",
       "             0.8701,     0.87056,     0.87099,     0.87121,     0.87143,     0.87165,     0.87187,     0.87209,     0.87322,     0.87344,     0.87366,     0.87389,     0.87411,     0.87433,     0.87538,     0.87591,     0.87638,      0.8769,     0.87748,     0.87811,     0.87878,     0.87914,     0.87977,\n",
       "            0.88003,     0.88029,     0.88055,     0.88082,     0.88215,     0.88229,     0.88244,     0.88258,     0.88272,     0.88287,     0.88301,     0.88315,     0.88349,     0.88392,     0.88436,     0.88462,     0.88489,     0.88515,     0.88542,     0.88562,     0.88578,     0.88594,      0.8861,\n",
       "            0.88626,     0.88642,     0.88658,     0.88681,     0.88725,     0.88769,     0.88927,     0.88968,     0.89008,     0.89067,     0.89136,     0.89148,     0.89157,     0.89166,     0.89175,     0.89184,     0.89194,     0.89203,     0.89212,     0.89221,      0.8923,     0.89239,     0.89248,\n",
       "            0.89261,     0.89502,     0.89618,     0.89662,     0.89707,     0.89902,     0.90146,     0.90235,      0.9028,     0.90325,     0.90431,     0.90556,       0.906,     0.90627,     0.90653,     0.90679,     0.90712,     0.90775,      0.9082,     0.90843,     0.90933,     0.90928,     0.90924,\n",
       "            0.91061,     0.91107,     0.91153,     0.91253,     0.91284,     0.91272,     0.91264,     0.91258,     0.91255,     0.91253,     0.91251,     0.91249,     0.91247,     0.91253,     0.91295,     0.91338,     0.91371,     0.91378,     0.91384,      0.9139,     0.91396,     0.91402,     0.91409,\n",
       "            0.91415,     0.91421,     0.91427,     0.91433,      0.9144,     0.91446,     0.91452,     0.91458,     0.91464,     0.91471,     0.91477,     0.91483,     0.91489,     0.91496,      0.9156,     0.91623,     0.91657,     0.91692,     0.91726,     0.91882,     0.91904,     0.91925,     0.91947,\n",
       "            0.91969,      0.9199,     0.92036,     0.92101,      0.9212,     0.92115,     0.92113,     0.92111,     0.92109,     0.92108,     0.92106,     0.92103,       0.921,     0.92097,     0.92095,     0.92151,     0.92217,     0.92219,     0.92215,     0.92211,     0.92327,     0.92325,     0.92323,\n",
       "             0.9232,     0.92462,     0.92576,     0.92566,     0.92565,     0.92564,     0.92563,     0.92562,     0.92561,      0.9256,     0.92559,     0.92558,     0.92557,     0.92574,     0.92619,     0.92663,      0.9275,     0.92961,     0.92988,     0.93015,     0.93042,     0.93069,     0.93085,\n",
       "            0.93095,     0.93104,     0.93114,     0.93124,     0.93133,     0.93143,     0.93153,     0.93162,     0.93172,     0.93181,     0.93191,     0.93201,      0.9321,     0.93209,     0.93208,     0.93207,     0.93205,     0.93204,     0.93202,     0.93191,     0.93191,      0.9319,     0.93189,\n",
       "            0.93188,     0.93188,     0.93187,     0.93186,     0.93185,     0.93185,     0.93184,     0.93183,     0.93182,     0.93182,     0.93181,     0.93181,      0.9318,      0.9318,     0.93179,     0.93179,     0.93178,     0.93178,     0.93177,     0.93177,     0.93176,     0.93176,     0.93175,\n",
       "            0.93175,     0.93174,     0.93174,     0.93173,     0.93173,     0.93172,     0.93168,     0.93161,     0.93159,     0.93157,     0.93155,     0.93153,     0.93147,     0.93228,      0.9327,     0.93276,     0.93289,     0.93303,     0.93317,     0.93331,     0.93344,     0.93358,     0.93372,\n",
       "            0.93385,     0.93399,     0.93391,     0.93389,     0.93387,     0.93384,     0.93382,     0.93371,     0.93369,     0.93367,     0.93365,     0.93363,     0.93351,     0.93348,     0.93346,     0.93344,     0.93498,     0.93523,     0.93548,     0.93574,     0.93599,     0.93623,     0.93647,\n",
       "             0.9367,     0.93693,     0.93716,      0.9374,     0.93759,     0.93776,     0.93792,     0.93808,     0.93825,     0.93841,     0.93858,     0.93874,     0.93884,     0.93875,     0.93866,     0.93859,     0.93856,     0.93852,     0.93874,      0.9393,     0.93986,     0.94011,     0.94035,\n",
       "            0.94058,     0.94082,     0.94105,     0.94158,     0.94271,      0.9428,      0.9429,     0.94299,     0.94309,     0.94318,     0.94328,     0.94337,     0.94347,     0.94356,     0.94366,     0.94375,     0.94384,     0.94394,     0.94403,     0.94556,     0.94569,     0.94582,     0.94595,\n",
       "            0.94608,     0.94621,     0.94634,     0.94647,      0.9466,     0.94673,     0.94682,     0.94681,     0.94679,     0.94678,     0.94676,     0.94675,     0.94826,     0.94839,     0.94851,     0.94864,     0.94876,     0.94889,     0.94901,     0.94914,     0.94926,     0.94939,     0.94951,\n",
       "            0.94955,     0.94954,     0.94954,     0.94953,     0.94952,     0.94951,     0.94951,      0.9495,     0.94949,     0.94948,     0.94939,     0.94937,     0.94934,     0.94925,     0.94924,     0.94922,      0.9492,     0.94918,     0.94944,     0.94985,     0.95027,     0.95201,     0.95196,\n",
       "            0.95185,     0.95181,     0.95177,     0.95172,     0.95169,     0.95166,     0.95159,      0.9515,     0.95149,     0.95147,     0.95146,     0.95137,     0.95136,     0.95135,     0.95134,     0.95134,     0.95133,     0.95132,     0.95131,     0.95131,      0.9513,     0.95158,     0.95257,\n",
       "            0.95279,     0.95285,     0.95291,     0.95297,     0.95303,     0.95309,     0.95315,     0.95321,     0.95327,     0.95333,     0.95339,     0.95345,     0.95351,     0.95357,     0.95363,     0.95369,     0.95375,     0.95381,     0.95387,     0.95393,     0.95399,     0.95405,      0.9541,\n",
       "            0.95416,     0.95419,     0.95416,     0.95414,     0.95463,     0.95559,     0.95554,     0.95572,     0.95605,     0.95638,     0.95672,     0.95698,     0.95691,     0.95687,     0.95676,     0.95671,     0.95668,     0.95665,     0.95662,     0.95659,     0.95932,     0.95954,     0.95951,\n",
       "            0.95949,     0.95947,     0.95945,     0.95937,     0.95937,     0.95937,     0.95936,     0.95936,     0.95936,     0.95935,     0.95935,     0.95935,     0.95934,     0.95934,     0.95934,     0.95934,     0.95933,     0.95933,     0.95933,     0.95932,     0.95932,     0.95932,     0.95931,\n",
       "            0.96017,     0.96089,     0.96103,     0.96116,      0.9613,     0.96143,     0.96157,      0.9617,     0.96183,     0.96197,      0.9621,     0.96224,     0.96228,     0.96221,     0.96209,     0.96207,     0.96205,     0.96203,     0.96202,     0.96201,       0.962,     0.96199,     0.96198,\n",
       "            0.96197,     0.96194,     0.96507,     0.96559,     0.96612,     0.96889,     0.97198,     0.97271,      0.9727,     0.97268,     0.97267,     0.97411,     0.97523,     0.97655,      0.9777,     0.97834,       0.979,     0.97981,     0.98052,     0.98051,     0.98049,     0.98047,     0.98045,\n",
       "            0.98042,     0.98042,     0.98041,      0.9804,     0.98039,     0.98037,     0.98024,      0.9802,     0.98282,     0.98544,     0.98628,     0.98671,      0.9867,     0.98669,     0.98662,     0.98662,     0.98661,     0.98661,      0.9866,     0.98658,     0.98655,     0.98654,     0.98647,\n",
       "             0.9864,     0.98639,     0.98638,     0.98638,     0.98637,     0.98634,     0.98634,     0.98633,     0.98633,     0.98801,     0.98967,     0.98988,     0.99307,     0.99306,     0.99304,     0.99303,       0.993,     0.99296,     0.99295,     0.99286,     0.99285,     0.99278,     0.99273,\n",
       "            0.99269,     0.99268,     0.99263,     0.99262,     0.99255,     0.99235,      0.9922,     0.99214,     0.99212,     0.99204,     0.99196,     0.99193,     0.99183,     0.99179,     0.99176,     0.99174,     0.99157,     0.99148,     0.99137,     0.99123,     0.99116,     0.99112,      0.9909,\n",
       "            0.99085,     0.99076,     0.99037,     0.99017,        0.99,     0.99488,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.97762,     0.97762,     0.97483,     0.97483,     0.96923,     0.96923,     0.96923,     0.96923,     0.96923,     0.96923,     0.96923,     0.96923,     0.96923,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,\n",
       "            0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,\n",
       "            0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96101,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,\n",
       "            0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.96084,     0.95943,     0.95833,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,\n",
       "            0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,     0.95804,\n",
       "            0.95804,     0.95778,     0.95623,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,\n",
       "            0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,\n",
       "            0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,\n",
       "            0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95524,     0.95519,     0.95442,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,\n",
       "            0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95385,     0.95266,     0.95245,     0.95245,     0.95245,     0.95245,     0.95245,     0.95245,     0.95245,     0.95245,\n",
       "            0.95245,     0.95245,     0.95245,     0.95245,     0.95245,      0.9524,       0.952,     0.95161,     0.95121,     0.95105,     0.95015,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,\n",
       "            0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,\n",
       "            0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,\n",
       "            0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94965,     0.94934,       0.949,     0.94866,     0.94832,     0.94685,     0.94685,     0.94685,     0.94685,     0.94685,     0.94685,     0.94685,     0.94653,     0.94525,     0.94443,\n",
       "            0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94406,     0.94126,     0.94126,\n",
       "            0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,\n",
       "            0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,\n",
       "            0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94126,     0.94093,     0.93986,     0.93973,     0.93925,     0.93877,\n",
       "            0.93846,     0.93846,     0.93846,     0.93846,     0.93747,     0.93603,     0.93513,     0.93442,     0.93407,     0.93382,     0.93357,     0.93332,     0.93307,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,\n",
       "            0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,     0.93287,\n",
       "            0.93287,     0.93287,     0.93287,     0.93287,     0.93201,     0.93132,     0.93108,     0.93084,      0.9306,     0.93036,     0.93013,     0.92979,     0.92944,     0.92908,     0.92872,     0.92867,     0.92867,     0.92823,     0.92776,     0.92728,     0.92559,      0.9253,     0.92502,\n",
       "            0.92473,     0.92448,     0.92428,     0.92305,     0.92291,     0.92277,     0.92262,     0.92248,     0.92234,     0.92219,     0.92205,     0.92191,     0.92176,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,\n",
       "            0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92168,     0.92148,     0.92128,     0.92107,     0.92087,     0.92066,     0.92046,     0.91887,     0.91876,     0.91865,     0.91854,\n",
       "            0.91843,     0.91831,      0.9182,     0.91809,     0.91798,     0.91787,     0.91776,     0.91765,     0.91754,     0.91745,     0.91738,     0.91731,     0.91724,     0.91717,      0.9171,     0.91703,     0.91696,     0.91689,     0.91682,     0.91675,     0.91668,     0.91661,     0.91654,\n",
       "            0.91647,      0.9164,     0.91633,     0.91626,     0.91619,     0.91612,     0.91544,     0.91455,     0.91426,     0.91398,     0.91369,      0.9134,     0.91243,     0.91189,     0.91096,     0.91049,     0.91049,     0.91049,     0.91049,     0.91049,     0.91049,     0.91049,     0.91049,\n",
       "            0.91049,     0.91049,     0.90918,     0.90879,     0.90847,     0.90815,     0.90784,     0.90614,     0.90585,     0.90556,     0.90528,     0.90499,     0.90326,      0.9029,     0.90254,     0.90218,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,\n",
       "             0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,      0.9021,     0.90173,     0.90029,     0.89886,     0.89774,     0.89727,     0.89679,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,\n",
       "             0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,\n",
       "             0.8965,      0.8965,      0.8965,      0.8965,      0.8965,      0.8965,     0.89644,     0.89618,     0.89591,     0.89565,     0.89539,     0.89513,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,      0.8951,\n",
       "            0.89501,     0.89488,     0.89474,      0.8946,     0.89447,     0.89433,     0.89419,     0.89406,     0.89392,     0.89378,      0.8921,     0.89162,     0.89115,     0.88951,     0.88919,     0.88887,     0.88855,     0.88823,     0.88811,     0.88811,     0.88811,     0.88791,     0.88695,\n",
       "            0.88478,     0.88406,     0.88315,     0.88233,     0.88175,     0.88118,     0.87984,     0.87806,     0.87777,     0.87748,      0.8772,     0.87552,     0.87538,     0.87523,     0.87509,     0.87495,      0.8748,     0.87466,     0.87452,     0.87437,     0.87423,     0.87413,     0.87413,\n",
       "            0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,     0.87413,\n",
       "            0.87413,     0.87392,     0.87344,     0.87296,     0.87273,     0.87269,     0.87173,     0.87133,     0.87133,     0.87133,     0.87133,     0.87106,     0.86973,     0.86877,     0.86642,     0.86553,     0.86481,     0.86414,     0.86357,       0.863,     0.86294,     0.86241,     0.86184,\n",
       "            0.86131,     0.86083,     0.86035,      0.8587,     0.85863,     0.85856,     0.85849,     0.85842,     0.85835,     0.85828,     0.85821,     0.85814,     0.85807,       0.858,     0.85793,     0.85786,     0.85779,     0.85772,     0.85765,     0.85758,     0.85751,     0.85744,     0.85737,\n",
       "            0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85734,     0.85631,     0.85469,     0.85197,     0.85137,     0.85096,     0.85055,     0.85023,     0.84999,     0.84975,     0.84951,     0.84927,\n",
       "            0.84903,     0.84833,     0.84755,     0.84755,     0.84755,     0.84755,     0.84755,     0.84742,     0.84701,     0.84661,      0.8462,     0.84615,     0.84615,     0.84615,     0.84615,     0.84615,     0.84615,     0.84615,      0.8447,     0.84413,     0.84355,     0.84273,     0.84168,\n",
       "            0.84049,     0.84017,     0.83985,     0.83954,     0.83922,     0.83837,     0.83253,     0.83091,     0.83077,     0.83077,     0.83077,     0.83054,     0.83006,     0.82958,     0.82515,     0.82483,     0.82452,      0.8242,     0.82388,      0.8228,     0.82077,     0.81982,      0.8157,\n",
       "            0.81176,      0.8109,     0.81054,     0.81018,     0.80983,     0.80811,     0.80779,     0.80747,     0.80715,      0.8042,     0.80413,      0.8014,     0.80131,     0.80035,     0.79819,     0.79658,     0.79386,      0.7886,     0.78765,     0.77826,     0.77651,     0.76878,     0.76406,\n",
       "            0.75962,     0.75819,     0.75345,      0.7525,     0.74553,     0.72588,     0.71183,     0.70578,     0.70469,     0.69763,     0.69057,      0.6877,     0.67924,     0.67595,     0.67312,     0.67168,     0.65798,     0.65092,     0.64246,     0.63259,     0.62745,     0.62462,      0.6092,\n",
       "            0.60574,     0.60008,     0.57553,     0.56357,     0.55371,     0.54385,     0.53539,     0.52413,     0.52217,     0.51141,     0.49875,     0.48889,     0.47903,     0.45378,     0.44812,     0.43311,      0.4242,     0.41294,     0.41133,     0.40581,     0.40294,     0.39868,     0.38742,\n",
       "            0.38036,     0.37189,     0.35504,     0.34881,     0.33392,     0.32217,     0.30581,     0.28476,     0.26651,     0.25525,     0.24119,     0.23525,     0.22287,     0.20462,     0.17658,     0.16392,     0.14847,     0.10924,    0.097976,    0.093009,    0.090177,    0.075389,    0.071123,\n",
       "           0.065458,    0.051633,    0.050677,    0.043114,    0.040467,    0.039989,    0.039511,    0.036996,    0.031332,    0.025421,    0.017694,    0.015737,    0.015191,    0.014971,     0.01475,     0.01453,    0.014309,    0.014088,    0.011052,   0.0067858,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.7993456282294186)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.78159])\n",
       "names: {0: 'golfball'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.9298818409143288), 'metrics/recall(B)': np.float64(0.9216783216783216), 'metrics/mAP50(B)': np.float64(0.9591334381763109), 'metrics/mAP50-95(B)': np.float64(0.7815914271242084), 'fitness': np.float64(0.7993456282294186)}\n",
       "save_dir: PosixPath('runs/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience')\n",
       "speed: {'preprocess': 0.2336023109299796, 'inference': 2.027271581547601, 'loss': 0.0006450074059622628, 'postprocess': 0.4931906504290444}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8n 모델 로드 (사전학습된 모델)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# 모델 학습 시작\n",
    "model.train(\n",
    "    data='./merged_golfball_with_golf_club/data.yaml',  # YAML 파일 경로\n",
    "    epochs=200, \n",
    "    imgsz=640, # 이미지 크기\n",
    "    batch=16,\n",
    "    name='yolov8n_golf_ball_merged_golfball_with_golf_club_150epoch_16batch_10patience',\n",
    "    patience=10,  # 10 epoch 동안 개선이 없으면 조기 종료\n",
    "    augment=True  # 데이터 증강 활성화, 여러 증강 기법들이 학습 과정에서 자동으로 적용, 여기에는 회전, 크기 조정, 좌우 반전, 밝기 및 대비 조정 등의 다양한 변환이 포함\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.27 🚀 Python-3.9.20 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24111MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/YOLOv8n_Golfball/merged_golfball/valid/labels.cache... 448 images, 1 backgrounds, 0 corrupt: 100%|██████████| 448/448 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 56/56 [00:03<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        448        715      0.931      0.922      0.959      0.783\n",
      "Speed: 0.3ms preprocess, 3.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolov8n_golf_ball_merged_data_100epoch_8batch_10patience2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터셋으로 모델 평가\n",
    "results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.7974</td>\n",
       "      <td>1.01952</td>\n",
       "      <td>1.53185</td>\n",
       "      <td>1.20647</td>\n",
       "      <td>0.80259</td>\n",
       "      <td>0.77491</td>\n",
       "      <td>0.79671</td>\n",
       "      <td>0.49691</td>\n",
       "      <td>1.16135</td>\n",
       "      <td>1.41043</td>\n",
       "      <td>1.37551</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31.7419</td>\n",
       "      <td>1.07298</td>\n",
       "      <td>1.17419</td>\n",
       "      <td>1.23323</td>\n",
       "      <td>0.85813</td>\n",
       "      <td>0.76864</td>\n",
       "      <td>0.82944</td>\n",
       "      <td>0.57584</td>\n",
       "      <td>1.04713</td>\n",
       "      <td>1.29217</td>\n",
       "      <td>1.25514</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45.4636</td>\n",
       "      <td>1.06847</td>\n",
       "      <td>1.02328</td>\n",
       "      <td>1.23297</td>\n",
       "      <td>0.84013</td>\n",
       "      <td>0.79834</td>\n",
       "      <td>0.83440</td>\n",
       "      <td>0.61019</td>\n",
       "      <td>0.95966</td>\n",
       "      <td>0.88772</td>\n",
       "      <td>1.19697</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>59.0101</td>\n",
       "      <td>1.04322</td>\n",
       "      <td>0.94504</td>\n",
       "      <td>1.22133</td>\n",
       "      <td>0.89720</td>\n",
       "      <td>0.82873</td>\n",
       "      <td>0.84483</td>\n",
       "      <td>0.62366</td>\n",
       "      <td>0.98856</td>\n",
       "      <td>0.80684</td>\n",
       "      <td>1.18422</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>72.5478</td>\n",
       "      <td>1.01203</td>\n",
       "      <td>0.88575</td>\n",
       "      <td>1.19647</td>\n",
       "      <td>0.87866</td>\n",
       "      <td>0.82597</td>\n",
       "      <td>0.86330</td>\n",
       "      <td>0.60810</td>\n",
       "      <td>1.00340</td>\n",
       "      <td>0.73188</td>\n",
       "      <td>1.20598</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>85.9300</td>\n",
       "      <td>0.99668</td>\n",
       "      <td>0.85178</td>\n",
       "      <td>1.19100</td>\n",
       "      <td>0.88926</td>\n",
       "      <td>0.84293</td>\n",
       "      <td>0.88276</td>\n",
       "      <td>0.66772</td>\n",
       "      <td>0.93437</td>\n",
       "      <td>0.65269</td>\n",
       "      <td>1.16236</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>99.3824</td>\n",
       "      <td>0.98235</td>\n",
       "      <td>0.77483</td>\n",
       "      <td>1.18446</td>\n",
       "      <td>0.88562</td>\n",
       "      <td>0.81281</td>\n",
       "      <td>0.86249</td>\n",
       "      <td>0.63525</td>\n",
       "      <td>0.94674</td>\n",
       "      <td>0.78779</td>\n",
       "      <td>1.15482</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>112.5970</td>\n",
       "      <td>0.95683</td>\n",
       "      <td>0.77778</td>\n",
       "      <td>1.16248</td>\n",
       "      <td>0.89974</td>\n",
       "      <td>0.81806</td>\n",
       "      <td>0.88123</td>\n",
       "      <td>0.66109</td>\n",
       "      <td>0.87685</td>\n",
       "      <td>0.70493</td>\n",
       "      <td>1.15583</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.001861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>126.0160</td>\n",
       "      <td>0.92254</td>\n",
       "      <td>0.74623</td>\n",
       "      <td>1.14646</td>\n",
       "      <td>0.94185</td>\n",
       "      <td>0.85635</td>\n",
       "      <td>0.90279</td>\n",
       "      <td>0.68057</td>\n",
       "      <td>0.90936</td>\n",
       "      <td>0.59504</td>\n",
       "      <td>1.13064</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>139.4550</td>\n",
       "      <td>0.92967</td>\n",
       "      <td>0.73042</td>\n",
       "      <td>1.14381</td>\n",
       "      <td>0.89874</td>\n",
       "      <td>0.85810</td>\n",
       "      <td>0.89501</td>\n",
       "      <td>0.68420</td>\n",
       "      <td>0.86295</td>\n",
       "      <td>0.59679</td>\n",
       "      <td>1.10322</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>152.9010</td>\n",
       "      <td>0.92654</td>\n",
       "      <td>0.70402</td>\n",
       "      <td>1.15365</td>\n",
       "      <td>0.88984</td>\n",
       "      <td>0.81768</td>\n",
       "      <td>0.88247</td>\n",
       "      <td>0.66090</td>\n",
       "      <td>0.89803</td>\n",
       "      <td>0.64214</td>\n",
       "      <td>1.11470</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>166.2640</td>\n",
       "      <td>0.89603</td>\n",
       "      <td>0.68644</td>\n",
       "      <td>1.12778</td>\n",
       "      <td>0.90351</td>\n",
       "      <td>0.85360</td>\n",
       "      <td>0.89291</td>\n",
       "      <td>0.67475</td>\n",
       "      <td>0.87085</td>\n",
       "      <td>0.59157</td>\n",
       "      <td>1.11126</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>179.6010</td>\n",
       "      <td>0.91328</td>\n",
       "      <td>0.69550</td>\n",
       "      <td>1.14228</td>\n",
       "      <td>0.93060</td>\n",
       "      <td>0.85194</td>\n",
       "      <td>0.90723</td>\n",
       "      <td>0.70783</td>\n",
       "      <td>0.83588</td>\n",
       "      <td>0.54958</td>\n",
       "      <td>1.07986</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.001762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>192.7140</td>\n",
       "      <td>0.88120</td>\n",
       "      <td>0.67219</td>\n",
       "      <td>1.12802</td>\n",
       "      <td>0.91425</td>\n",
       "      <td>0.87017</td>\n",
       "      <td>0.91175</td>\n",
       "      <td>0.69945</td>\n",
       "      <td>0.83773</td>\n",
       "      <td>0.53198</td>\n",
       "      <td>1.11329</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.001743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>205.7980</td>\n",
       "      <td>0.86785</td>\n",
       "      <td>0.64769</td>\n",
       "      <td>1.11963</td>\n",
       "      <td>0.93206</td>\n",
       "      <td>0.87170</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.70708</td>\n",
       "      <td>0.83384</td>\n",
       "      <td>0.50101</td>\n",
       "      <td>1.10849</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>218.8990</td>\n",
       "      <td>0.86786</td>\n",
       "      <td>0.64632</td>\n",
       "      <td>1.11543</td>\n",
       "      <td>0.91459</td>\n",
       "      <td>0.82873</td>\n",
       "      <td>0.89865</td>\n",
       "      <td>0.69229</td>\n",
       "      <td>0.85857</td>\n",
       "      <td>0.57011</td>\n",
       "      <td>1.09540</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>232.0830</td>\n",
       "      <td>0.86486</td>\n",
       "      <td>0.64611</td>\n",
       "      <td>1.11779</td>\n",
       "      <td>0.90092</td>\n",
       "      <td>0.89227</td>\n",
       "      <td>0.91203</td>\n",
       "      <td>0.69947</td>\n",
       "      <td>0.84290</td>\n",
       "      <td>0.51215</td>\n",
       "      <td>1.09158</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>245.1500</td>\n",
       "      <td>0.85491</td>\n",
       "      <td>0.63981</td>\n",
       "      <td>1.10847</td>\n",
       "      <td>0.89484</td>\n",
       "      <td>0.87569</td>\n",
       "      <td>0.91829</td>\n",
       "      <td>0.70438</td>\n",
       "      <td>0.83941</td>\n",
       "      <td>0.51151</td>\n",
       "      <td>1.07252</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>258.2370</td>\n",
       "      <td>0.85131</td>\n",
       "      <td>0.61237</td>\n",
       "      <td>1.11015</td>\n",
       "      <td>0.91762</td>\n",
       "      <td>0.89237</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.70597</td>\n",
       "      <td>0.79637</td>\n",
       "      <td>0.48978</td>\n",
       "      <td>1.07643</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>270.9880</td>\n",
       "      <td>0.85203</td>\n",
       "      <td>0.60806</td>\n",
       "      <td>1.10932</td>\n",
       "      <td>0.92004</td>\n",
       "      <td>0.88398</td>\n",
       "      <td>0.92138</td>\n",
       "      <td>0.71245</td>\n",
       "      <td>0.81757</td>\n",
       "      <td>0.49651</td>\n",
       "      <td>1.10220</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>283.8580</td>\n",
       "      <td>0.84781</td>\n",
       "      <td>0.60460</td>\n",
       "      <td>1.10987</td>\n",
       "      <td>0.92983</td>\n",
       "      <td>0.84254</td>\n",
       "      <td>0.91628</td>\n",
       "      <td>0.70774</td>\n",
       "      <td>0.83854</td>\n",
       "      <td>0.52532</td>\n",
       "      <td>1.09921</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>297.0260</td>\n",
       "      <td>0.83568</td>\n",
       "      <td>0.58808</td>\n",
       "      <td>1.09331</td>\n",
       "      <td>0.87778</td>\n",
       "      <td>0.87294</td>\n",
       "      <td>0.92178</td>\n",
       "      <td>0.70590</td>\n",
       "      <td>0.82556</td>\n",
       "      <td>0.54430</td>\n",
       "      <td>1.10313</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>310.2710</td>\n",
       "      <td>0.82730</td>\n",
       "      <td>0.57689</td>\n",
       "      <td>1.09361</td>\n",
       "      <td>0.92974</td>\n",
       "      <td>0.87729</td>\n",
       "      <td>0.92703</td>\n",
       "      <td>0.71648</td>\n",
       "      <td>0.81912</td>\n",
       "      <td>0.46670</td>\n",
       "      <td>1.06936</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.001564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>323.4960</td>\n",
       "      <td>0.83382</td>\n",
       "      <td>0.59273</td>\n",
       "      <td>1.09587</td>\n",
       "      <td>0.88638</td>\n",
       "      <td>0.90331</td>\n",
       "      <td>0.93584</td>\n",
       "      <td>0.72757</td>\n",
       "      <td>0.84406</td>\n",
       "      <td>0.46577</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.001545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>336.6830</td>\n",
       "      <td>0.82775</td>\n",
       "      <td>0.57648</td>\n",
       "      <td>1.09240</td>\n",
       "      <td>0.91486</td>\n",
       "      <td>0.86077</td>\n",
       "      <td>0.92468</td>\n",
       "      <td>0.71085</td>\n",
       "      <td>0.80879</td>\n",
       "      <td>0.51045</td>\n",
       "      <td>1.07979</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>349.7480</td>\n",
       "      <td>0.82668</td>\n",
       "      <td>0.57686</td>\n",
       "      <td>1.09681</td>\n",
       "      <td>0.94244</td>\n",
       "      <td>0.87017</td>\n",
       "      <td>0.93339</td>\n",
       "      <td>0.72176</td>\n",
       "      <td>0.79909</td>\n",
       "      <td>0.50467</td>\n",
       "      <td>1.08505</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>362.8790</td>\n",
       "      <td>0.82746</td>\n",
       "      <td>0.57503</td>\n",
       "      <td>1.09063</td>\n",
       "      <td>0.93404</td>\n",
       "      <td>0.84254</td>\n",
       "      <td>0.91397</td>\n",
       "      <td>0.72855</td>\n",
       "      <td>0.79438</td>\n",
       "      <td>0.47946</td>\n",
       "      <td>1.06730</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>375.5840</td>\n",
       "      <td>0.80157</td>\n",
       "      <td>0.55944</td>\n",
       "      <td>1.07917</td>\n",
       "      <td>0.91752</td>\n",
       "      <td>0.86041</td>\n",
       "      <td>0.92917</td>\n",
       "      <td>0.71924</td>\n",
       "      <td>0.80085</td>\n",
       "      <td>0.49541</td>\n",
       "      <td>1.07394</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>388.3770</td>\n",
       "      <td>0.81690</td>\n",
       "      <td>0.56153</td>\n",
       "      <td>1.08223</td>\n",
       "      <td>0.90519</td>\n",
       "      <td>0.86188</td>\n",
       "      <td>0.91763</td>\n",
       "      <td>0.72059</td>\n",
       "      <td>0.79062</td>\n",
       "      <td>0.46601</td>\n",
       "      <td>1.06023</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>401.5470</td>\n",
       "      <td>0.81080</td>\n",
       "      <td>0.56951</td>\n",
       "      <td>1.08065</td>\n",
       "      <td>0.94026</td>\n",
       "      <td>0.88122</td>\n",
       "      <td>0.93259</td>\n",
       "      <td>0.72076</td>\n",
       "      <td>0.79468</td>\n",
       "      <td>0.44887</td>\n",
       "      <td>1.06256</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>414.6560</td>\n",
       "      <td>0.81101</td>\n",
       "      <td>0.56258</td>\n",
       "      <td>1.08455</td>\n",
       "      <td>0.95719</td>\n",
       "      <td>0.86473</td>\n",
       "      <td>0.93407</td>\n",
       "      <td>0.72495</td>\n",
       "      <td>0.81068</td>\n",
       "      <td>0.49602</td>\n",
       "      <td>1.06946</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>427.3970</td>\n",
       "      <td>0.79301</td>\n",
       "      <td>0.55429</td>\n",
       "      <td>1.06708</td>\n",
       "      <td>0.91938</td>\n",
       "      <td>0.88207</td>\n",
       "      <td>0.93256</td>\n",
       "      <td>0.72640</td>\n",
       "      <td>0.80112</td>\n",
       "      <td>0.47158</td>\n",
       "      <td>1.05501</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>440.6230</td>\n",
       "      <td>0.78662</td>\n",
       "      <td>0.54000</td>\n",
       "      <td>1.07611</td>\n",
       "      <td>0.92441</td>\n",
       "      <td>0.88398</td>\n",
       "      <td>0.93220</td>\n",
       "      <td>0.73260</td>\n",
       "      <td>0.78508</td>\n",
       "      <td>0.45605</td>\n",
       "      <td>1.06632</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>453.5540</td>\n",
       "      <td>0.79398</td>\n",
       "      <td>0.54052</td>\n",
       "      <td>1.07071</td>\n",
       "      <td>0.91614</td>\n",
       "      <td>0.90055</td>\n",
       "      <td>0.93453</td>\n",
       "      <td>0.72726</td>\n",
       "      <td>0.79340</td>\n",
       "      <td>0.45312</td>\n",
       "      <td>1.06557</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>466.2910</td>\n",
       "      <td>0.78621</td>\n",
       "      <td>0.53162</td>\n",
       "      <td>1.06592</td>\n",
       "      <td>0.93565</td>\n",
       "      <td>0.88365</td>\n",
       "      <td>0.92865</td>\n",
       "      <td>0.72635</td>\n",
       "      <td>0.80261</td>\n",
       "      <td>0.48985</td>\n",
       "      <td>1.06586</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>479.0900</td>\n",
       "      <td>0.78570</td>\n",
       "      <td>0.54266</td>\n",
       "      <td>1.07819</td>\n",
       "      <td>0.94232</td>\n",
       "      <td>0.85752</td>\n",
       "      <td>0.92861</td>\n",
       "      <td>0.73047</td>\n",
       "      <td>0.79257</td>\n",
       "      <td>0.47707</td>\n",
       "      <td>1.07070</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>493.0830</td>\n",
       "      <td>0.77399</td>\n",
       "      <td>0.52023</td>\n",
       "      <td>1.06862</td>\n",
       "      <td>0.93781</td>\n",
       "      <td>0.86464</td>\n",
       "      <td>0.93175</td>\n",
       "      <td>0.71948</td>\n",
       "      <td>0.81639</td>\n",
       "      <td>0.46151</td>\n",
       "      <td>1.08590</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>506.5920</td>\n",
       "      <td>0.77022</td>\n",
       "      <td>0.51453</td>\n",
       "      <td>1.06457</td>\n",
       "      <td>0.94274</td>\n",
       "      <td>0.87293</td>\n",
       "      <td>0.94033</td>\n",
       "      <td>0.74101</td>\n",
       "      <td>0.76465</td>\n",
       "      <td>0.44210</td>\n",
       "      <td>1.04522</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>519.5080</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>0.51575</td>\n",
       "      <td>1.06505</td>\n",
       "      <td>0.89276</td>\n",
       "      <td>0.91989</td>\n",
       "      <td>0.94020</td>\n",
       "      <td>0.72838</td>\n",
       "      <td>0.79781</td>\n",
       "      <td>0.45392</td>\n",
       "      <td>1.08004</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>532.1270</td>\n",
       "      <td>0.78333</td>\n",
       "      <td>0.52093</td>\n",
       "      <td>1.06409</td>\n",
       "      <td>0.93023</td>\n",
       "      <td>0.88390</td>\n",
       "      <td>0.94303</td>\n",
       "      <td>0.74922</td>\n",
       "      <td>0.77306</td>\n",
       "      <td>0.43013</td>\n",
       "      <td>1.05602</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>544.8410</td>\n",
       "      <td>0.76677</td>\n",
       "      <td>0.51462</td>\n",
       "      <td>1.06040</td>\n",
       "      <td>0.94424</td>\n",
       "      <td>0.88874</td>\n",
       "      <td>0.93223</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>0.78437</td>\n",
       "      <td>0.43439</td>\n",
       "      <td>1.07260</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>557.4260</td>\n",
       "      <td>0.75953</td>\n",
       "      <td>0.50546</td>\n",
       "      <td>1.05942</td>\n",
       "      <td>0.91507</td>\n",
       "      <td>0.89503</td>\n",
       "      <td>0.94234</td>\n",
       "      <td>0.74723</td>\n",
       "      <td>0.75043</td>\n",
       "      <td>0.42802</td>\n",
       "      <td>1.05250</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>570.0230</td>\n",
       "      <td>0.78124</td>\n",
       "      <td>0.50539</td>\n",
       "      <td>1.06590</td>\n",
       "      <td>0.94589</td>\n",
       "      <td>0.86914</td>\n",
       "      <td>0.94134</td>\n",
       "      <td>0.75121</td>\n",
       "      <td>0.76409</td>\n",
       "      <td>0.41651</td>\n",
       "      <td>1.05820</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>582.7380</td>\n",
       "      <td>0.76353</td>\n",
       "      <td>0.50857</td>\n",
       "      <td>1.05610</td>\n",
       "      <td>0.92905</td>\n",
       "      <td>0.89503</td>\n",
       "      <td>0.93948</td>\n",
       "      <td>0.73806</td>\n",
       "      <td>0.76898</td>\n",
       "      <td>0.43071</td>\n",
       "      <td>1.06058</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>595.3230</td>\n",
       "      <td>0.74970</td>\n",
       "      <td>0.48794</td>\n",
       "      <td>1.05278</td>\n",
       "      <td>0.90556</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>0.94718</td>\n",
       "      <td>0.75124</td>\n",
       "      <td>0.78645</td>\n",
       "      <td>0.43934</td>\n",
       "      <td>1.06917</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>608.2340</td>\n",
       "      <td>0.74554</td>\n",
       "      <td>0.48737</td>\n",
       "      <td>1.05878</td>\n",
       "      <td>0.89928</td>\n",
       "      <td>0.91255</td>\n",
       "      <td>0.93674</td>\n",
       "      <td>0.74327</td>\n",
       "      <td>0.77357</td>\n",
       "      <td>0.42903</td>\n",
       "      <td>1.06439</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>621.3660</td>\n",
       "      <td>0.75006</td>\n",
       "      <td>0.48857</td>\n",
       "      <td>1.05261</td>\n",
       "      <td>0.97143</td>\n",
       "      <td>0.84535</td>\n",
       "      <td>0.93818</td>\n",
       "      <td>0.74272</td>\n",
       "      <td>0.76425</td>\n",
       "      <td>0.42600</td>\n",
       "      <td>1.06191</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>634.2560</td>\n",
       "      <td>0.74478</td>\n",
       "      <td>0.48043</td>\n",
       "      <td>1.05185</td>\n",
       "      <td>0.92283</td>\n",
       "      <td>0.91989</td>\n",
       "      <td>0.95697</td>\n",
       "      <td>0.76254</td>\n",
       "      <td>0.78182</td>\n",
       "      <td>0.39844</td>\n",
       "      <td>1.05879</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>647.4900</td>\n",
       "      <td>0.73980</td>\n",
       "      <td>0.47814</td>\n",
       "      <td>1.05408</td>\n",
       "      <td>0.92438</td>\n",
       "      <td>0.91173</td>\n",
       "      <td>0.95466</td>\n",
       "      <td>0.74716</td>\n",
       "      <td>0.79849</td>\n",
       "      <td>0.42810</td>\n",
       "      <td>1.07660</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>660.7830</td>\n",
       "      <td>0.73651</td>\n",
       "      <td>0.48575</td>\n",
       "      <td>1.05163</td>\n",
       "      <td>0.92439</td>\n",
       "      <td>0.89503</td>\n",
       "      <td>0.94906</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0.72637</td>\n",
       "      <td>0.42050</td>\n",
       "      <td>1.04158</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>674.1190</td>\n",
       "      <td>0.74019</td>\n",
       "      <td>0.47610</td>\n",
       "      <td>1.04263</td>\n",
       "      <td>0.94023</td>\n",
       "      <td>0.86740</td>\n",
       "      <td>0.94349</td>\n",
       "      <td>0.73524</td>\n",
       "      <td>0.81493</td>\n",
       "      <td>0.47627</td>\n",
       "      <td>1.07577</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>687.5320</td>\n",
       "      <td>0.74143</td>\n",
       "      <td>0.46510</td>\n",
       "      <td>1.04231</td>\n",
       "      <td>0.95334</td>\n",
       "      <td>0.84669</td>\n",
       "      <td>0.92727</td>\n",
       "      <td>0.73752</td>\n",
       "      <td>0.77235</td>\n",
       "      <td>0.42564</td>\n",
       "      <td>1.05784</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>700.8760</td>\n",
       "      <td>0.73470</td>\n",
       "      <td>0.46362</td>\n",
       "      <td>1.03724</td>\n",
       "      <td>0.93092</td>\n",
       "      <td>0.87017</td>\n",
       "      <td>0.93461</td>\n",
       "      <td>0.75296</td>\n",
       "      <td>0.75589</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>1.05677</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>714.2030</td>\n",
       "      <td>0.72784</td>\n",
       "      <td>0.46808</td>\n",
       "      <td>1.04266</td>\n",
       "      <td>0.95773</td>\n",
       "      <td>0.87626</td>\n",
       "      <td>0.94049</td>\n",
       "      <td>0.74831</td>\n",
       "      <td>0.79234</td>\n",
       "      <td>0.41672</td>\n",
       "      <td>1.07434</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>727.1460</td>\n",
       "      <td>0.72762</td>\n",
       "      <td>0.46274</td>\n",
       "      <td>1.04609</td>\n",
       "      <td>0.92401</td>\n",
       "      <td>0.90331</td>\n",
       "      <td>0.95185</td>\n",
       "      <td>0.75443</td>\n",
       "      <td>0.75260</td>\n",
       "      <td>0.40220</td>\n",
       "      <td>1.04596</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>740.2050</td>\n",
       "      <td>0.72028</td>\n",
       "      <td>0.46493</td>\n",
       "      <td>1.03501</td>\n",
       "      <td>0.92368</td>\n",
       "      <td>0.90269</td>\n",
       "      <td>0.95338</td>\n",
       "      <td>0.76027</td>\n",
       "      <td>0.74391</td>\n",
       "      <td>0.41502</td>\n",
       "      <td>1.05146</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>753.1940</td>\n",
       "      <td>0.71235</td>\n",
       "      <td>0.45250</td>\n",
       "      <td>1.03065</td>\n",
       "      <td>0.93225</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>0.95788</td>\n",
       "      <td>0.75960</td>\n",
       "      <td>0.77092</td>\n",
       "      <td>0.40347</td>\n",
       "      <td>1.05601</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>766.1470</td>\n",
       "      <td>0.72731</td>\n",
       "      <td>0.46659</td>\n",
       "      <td>1.04254</td>\n",
       "      <td>0.89793</td>\n",
       "      <td>0.91713</td>\n",
       "      <td>0.95525</td>\n",
       "      <td>0.76241</td>\n",
       "      <td>0.75116</td>\n",
       "      <td>0.41282</td>\n",
       "      <td>1.04697</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      time  train/box_loss  train/cls_loss  train/dfl_loss  \\\n",
       "0       1   17.7974         1.01952         1.53185         1.20647   \n",
       "1       2   31.7419         1.07298         1.17419         1.23323   \n",
       "2       3   45.4636         1.06847         1.02328         1.23297   \n",
       "3       4   59.0101         1.04322         0.94504         1.22133   \n",
       "4       5   72.5478         1.01203         0.88575         1.19647   \n",
       "5       6   85.9300         0.99668         0.85178         1.19100   \n",
       "6       7   99.3824         0.98235         0.77483         1.18446   \n",
       "7       8  112.5970         0.95683         0.77778         1.16248   \n",
       "8       9  126.0160         0.92254         0.74623         1.14646   \n",
       "9      10  139.4550         0.92967         0.73042         1.14381   \n",
       "10     11  152.9010         0.92654         0.70402         1.15365   \n",
       "11     12  166.2640         0.89603         0.68644         1.12778   \n",
       "12     13  179.6010         0.91328         0.69550         1.14228   \n",
       "13     14  192.7140         0.88120         0.67219         1.12802   \n",
       "14     15  205.7980         0.86785         0.64769         1.11963   \n",
       "15     16  218.8990         0.86786         0.64632         1.11543   \n",
       "16     17  232.0830         0.86486         0.64611         1.11779   \n",
       "17     18  245.1500         0.85491         0.63981         1.10847   \n",
       "18     19  258.2370         0.85131         0.61237         1.11015   \n",
       "19     20  270.9880         0.85203         0.60806         1.10932   \n",
       "20     21  283.8580         0.84781         0.60460         1.10987   \n",
       "21     22  297.0260         0.83568         0.58808         1.09331   \n",
       "22     23  310.2710         0.82730         0.57689         1.09361   \n",
       "23     24  323.4960         0.83382         0.59273         1.09587   \n",
       "24     25  336.6830         0.82775         0.57648         1.09240   \n",
       "25     26  349.7480         0.82668         0.57686         1.09681   \n",
       "26     27  362.8790         0.82746         0.57503         1.09063   \n",
       "27     28  375.5840         0.80157         0.55944         1.07917   \n",
       "28     29  388.3770         0.81690         0.56153         1.08223   \n",
       "29     30  401.5470         0.81080         0.56951         1.08065   \n",
       "30     31  414.6560         0.81101         0.56258         1.08455   \n",
       "31     32  427.3970         0.79301         0.55429         1.06708   \n",
       "32     33  440.6230         0.78662         0.54000         1.07611   \n",
       "33     34  453.5540         0.79398         0.54052         1.07071   \n",
       "34     35  466.2910         0.78621         0.53162         1.06592   \n",
       "35     36  479.0900         0.78570         0.54266         1.07819   \n",
       "36     37  493.0830         0.77399         0.52023         1.06862   \n",
       "37     38  506.5920         0.77022         0.51453         1.06457   \n",
       "38     39  519.5080         0.77560         0.51575         1.06505   \n",
       "39     40  532.1270         0.78333         0.52093         1.06409   \n",
       "40     41  544.8410         0.76677         0.51462         1.06040   \n",
       "41     42  557.4260         0.75953         0.50546         1.05942   \n",
       "42     43  570.0230         0.78124         0.50539         1.06590   \n",
       "43     44  582.7380         0.76353         0.50857         1.05610   \n",
       "44     45  595.3230         0.74970         0.48794         1.05278   \n",
       "45     46  608.2340         0.74554         0.48737         1.05878   \n",
       "46     47  621.3660         0.75006         0.48857         1.05261   \n",
       "47     48  634.2560         0.74478         0.48043         1.05185   \n",
       "48     49  647.4900         0.73980         0.47814         1.05408   \n",
       "49     50  660.7830         0.73651         0.48575         1.05163   \n",
       "50     51  674.1190         0.74019         0.47610         1.04263   \n",
       "51     52  687.5320         0.74143         0.46510         1.04231   \n",
       "52     53  700.8760         0.73470         0.46362         1.03724   \n",
       "53     54  714.2030         0.72784         0.46808         1.04266   \n",
       "54     55  727.1460         0.72762         0.46274         1.04609   \n",
       "55     56  740.2050         0.72028         0.46493         1.03501   \n",
       "56     57  753.1940         0.71235         0.45250         1.03065   \n",
       "57     58  766.1470         0.72731         0.46659         1.04254   \n",
       "\n",
       "    metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "0                0.80259            0.77491           0.79671   \n",
       "1                0.85813            0.76864           0.82944   \n",
       "2                0.84013            0.79834           0.83440   \n",
       "3                0.89720            0.82873           0.84483   \n",
       "4                0.87866            0.82597           0.86330   \n",
       "5                0.88926            0.84293           0.88276   \n",
       "6                0.88562            0.81281           0.86249   \n",
       "7                0.89974            0.81806           0.88123   \n",
       "8                0.94185            0.85635           0.90279   \n",
       "9                0.89874            0.85810           0.89501   \n",
       "10               0.88984            0.81768           0.88247   \n",
       "11               0.90351            0.85360           0.89291   \n",
       "12               0.93060            0.85194           0.90723   \n",
       "13               0.91425            0.87017           0.91175   \n",
       "14               0.93206            0.87170           0.91483   \n",
       "15               0.91459            0.82873           0.89865   \n",
       "16               0.90092            0.89227           0.91203   \n",
       "17               0.89484            0.87569           0.91829   \n",
       "18               0.91762            0.89237           0.91519   \n",
       "19               0.92004            0.88398           0.92138   \n",
       "20               0.92983            0.84254           0.91628   \n",
       "21               0.87778            0.87294           0.92178   \n",
       "22               0.92974            0.87729           0.92703   \n",
       "23               0.88638            0.90331           0.93584   \n",
       "24               0.91486            0.86077           0.92468   \n",
       "25               0.94244            0.87017           0.93339   \n",
       "26               0.93404            0.84254           0.91397   \n",
       "27               0.91752            0.86041           0.92917   \n",
       "28               0.90519            0.86188           0.91763   \n",
       "29               0.94026            0.88122           0.93259   \n",
       "30               0.95719            0.86473           0.93407   \n",
       "31               0.91938            0.88207           0.93256   \n",
       "32               0.92441            0.88398           0.93220   \n",
       "33               0.91614            0.90055           0.93453   \n",
       "34               0.93565            0.88365           0.92865   \n",
       "35               0.94232            0.85752           0.92861   \n",
       "36               0.93781            0.86464           0.93175   \n",
       "37               0.94274            0.87293           0.94033   \n",
       "38               0.89276            0.91989           0.94020   \n",
       "39               0.93023            0.88390           0.94303   \n",
       "40               0.94424            0.88874           0.93223   \n",
       "41               0.91507            0.89503           0.94234   \n",
       "42               0.94589            0.86914           0.94134   \n",
       "43               0.92905            0.89503           0.93948   \n",
       "44               0.90556            0.90608           0.94718   \n",
       "45               0.89928            0.91255           0.93674   \n",
       "46               0.97143            0.84535           0.93818   \n",
       "47               0.92283            0.91989           0.95697   \n",
       "48               0.92438            0.91173           0.95466   \n",
       "49               0.92439            0.89503           0.94906   \n",
       "50               0.94023            0.86740           0.94349   \n",
       "51               0.95334            0.84669           0.92727   \n",
       "52               0.93092            0.87017           0.93461   \n",
       "53               0.95773            0.87626           0.94049   \n",
       "54               0.92401            0.90331           0.95185   \n",
       "55               0.92368            0.90269           0.95338   \n",
       "56               0.93225            0.90608           0.95788   \n",
       "57               0.89793            0.91713           0.95525   \n",
       "\n",
       "    metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss    lr/pg0  \\\n",
       "0               0.49691       1.16135       1.41043       1.37551  0.000664   \n",
       "1               0.57584       1.04713       1.29217       1.25514  0.001318   \n",
       "2               0.61019       0.95966       0.88772       1.19697  0.001958   \n",
       "3               0.62366       0.98856       0.80684       1.18422  0.001941   \n",
       "4               0.60810       1.00340       0.73188       1.20598  0.001921   \n",
       "5               0.66772       0.93437       0.65269       1.16236  0.001901   \n",
       "6               0.63525       0.94674       0.78779       1.15482  0.001881   \n",
       "7               0.66109       0.87685       0.70493       1.15583  0.001861   \n",
       "8               0.68057       0.90936       0.59504       1.13064  0.001842   \n",
       "9               0.68420       0.86295       0.59679       1.10322  0.001822   \n",
       "10              0.66090       0.89803       0.64214       1.11470  0.001802   \n",
       "11              0.67475       0.87085       0.59157       1.11126  0.001782   \n",
       "12              0.70783       0.83588       0.54958       1.07986  0.001762   \n",
       "13              0.69945       0.83773       0.53198       1.11329  0.001743   \n",
       "14              0.70708       0.83384       0.50101       1.10849  0.001723   \n",
       "15              0.69229       0.85857       0.57011       1.09540  0.001703   \n",
       "16              0.69947       0.84290       0.51215       1.09158  0.001683   \n",
       "17              0.70438       0.83941       0.51151       1.07252  0.001663   \n",
       "18              0.70597       0.79637       0.48978       1.07643  0.001644   \n",
       "19              0.71245       0.81757       0.49651       1.10220  0.001624   \n",
       "20              0.70774       0.83854       0.52532       1.09921  0.001604   \n",
       "21              0.70590       0.82556       0.54430       1.10313  0.001584   \n",
       "22              0.71648       0.81912       0.46670       1.06936  0.001564   \n",
       "23              0.72757       0.84406       0.46577       1.08030  0.001545   \n",
       "24              0.71085       0.80879       0.51045       1.07979  0.001525   \n",
       "25              0.72176       0.79909       0.50467       1.08505  0.001505   \n",
       "26              0.72855       0.79438       0.47946       1.06730  0.001485   \n",
       "27              0.71924       0.80085       0.49541       1.07394  0.001465   \n",
       "28              0.72059       0.79062       0.46601       1.06023  0.001446   \n",
       "29              0.72076       0.79468       0.44887       1.06256  0.001426   \n",
       "30              0.72495       0.81068       0.49602       1.06946  0.001406   \n",
       "31              0.72640       0.80112       0.47158       1.05501  0.001386   \n",
       "32              0.73260       0.78508       0.45605       1.06632  0.001366   \n",
       "33              0.72726       0.79340       0.45312       1.06557  0.001347   \n",
       "34              0.72635       0.80261       0.48985       1.06586  0.001327   \n",
       "35              0.73047       0.79257       0.47707       1.07070  0.001307   \n",
       "36              0.71948       0.81639       0.46151       1.08590  0.001287   \n",
       "37              0.74101       0.76465       0.44210       1.04522  0.001267   \n",
       "38              0.72838       0.79781       0.45392       1.08004  0.001248   \n",
       "39              0.74922       0.77306       0.43013       1.05602  0.001228   \n",
       "40              0.73494       0.78437       0.43439       1.07260  0.001208   \n",
       "41              0.74723       0.75043       0.42802       1.05250  0.001188   \n",
       "42              0.75121       0.76409       0.41651       1.05820  0.001168   \n",
       "43              0.73806       0.76898       0.43071       1.06058  0.001149   \n",
       "44              0.75124       0.78645       0.43934       1.06917  0.001129   \n",
       "45              0.74327       0.77357       0.42903       1.06439  0.001109   \n",
       "46              0.74272       0.76425       0.42600       1.06191  0.001089   \n",
       "47              0.76254       0.78182       0.39844       1.05879  0.001069   \n",
       "48              0.74716       0.79849       0.42810       1.07660  0.001050   \n",
       "49              0.75612       0.72637       0.42050       1.04158  0.001030   \n",
       "50              0.73524       0.81493       0.47627       1.07577  0.001010   \n",
       "51              0.73752       0.77235       0.42564       1.05784  0.000990   \n",
       "52              0.75296       0.75589       0.41594       1.05677  0.000970   \n",
       "53              0.74831       0.79234       0.41672       1.07434  0.000951   \n",
       "54              0.75443       0.75260       0.40220       1.04596  0.000931   \n",
       "55              0.76027       0.74391       0.41502       1.05146  0.000911   \n",
       "56              0.75960       0.77092       0.40347       1.05601  0.000891   \n",
       "57              0.76241       0.75116       0.41282       1.04697  0.000871   \n",
       "\n",
       "      lr/pg1    lr/pg2  \n",
       "0   0.000664  0.000664  \n",
       "1   0.001318  0.001318  \n",
       "2   0.001958  0.001958  \n",
       "3   0.001941  0.001941  \n",
       "4   0.001921  0.001921  \n",
       "5   0.001901  0.001901  \n",
       "6   0.001881  0.001881  \n",
       "7   0.001861  0.001861  \n",
       "8   0.001842  0.001842  \n",
       "9   0.001822  0.001822  \n",
       "10  0.001802  0.001802  \n",
       "11  0.001782  0.001782  \n",
       "12  0.001762  0.001762  \n",
       "13  0.001743  0.001743  \n",
       "14  0.001723  0.001723  \n",
       "15  0.001703  0.001703  \n",
       "16  0.001683  0.001683  \n",
       "17  0.001663  0.001663  \n",
       "18  0.001644  0.001644  \n",
       "19  0.001624  0.001624  \n",
       "20  0.001604  0.001604  \n",
       "21  0.001584  0.001584  \n",
       "22  0.001564  0.001564  \n",
       "23  0.001545  0.001545  \n",
       "24  0.001525  0.001525  \n",
       "25  0.001505  0.001505  \n",
       "26  0.001485  0.001485  \n",
       "27  0.001465  0.001465  \n",
       "28  0.001446  0.001446  \n",
       "29  0.001426  0.001426  \n",
       "30  0.001406  0.001406  \n",
       "31  0.001386  0.001386  \n",
       "32  0.001366  0.001366  \n",
       "33  0.001347  0.001347  \n",
       "34  0.001327  0.001327  \n",
       "35  0.001307  0.001307  \n",
       "36  0.001287  0.001287  \n",
       "37  0.001267  0.001267  \n",
       "38  0.001248  0.001248  \n",
       "39  0.001228  0.001228  \n",
       "40  0.001208  0.001208  \n",
       "41  0.001188  0.001188  \n",
       "42  0.001168  0.001168  \n",
       "43  0.001149  0.001149  \n",
       "44  0.001129  0.001129  \n",
       "45  0.001109  0.001109  \n",
       "46  0.001089  0.001089  \n",
       "47  0.001069  0.001069  \n",
       "48  0.001050  0.001050  \n",
       "49  0.001030  0.001030  \n",
       "50  0.001010  0.001010  \n",
       "51  0.000990  0.000990  \n",
       "52  0.000970  0.000970  \n",
       "53  0.000951  0.000951  \n",
       "54  0.000931  0.000931  \n",
       "55  0.000911  0.000911  \n",
       "56  0.000891  0.000891  \n",
       "57  0.000871  0.000871  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.read_csv('/root/YOLO_GOLF/runs/detect/yolov8n_golf_ball_100epoch_10patience_8batch/results.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /root/YOLO_GOLF/GolfBallDetector-10/test/images/6ced8d90b264f0ac_jpg.rf.d6f2a323158e8412ae30ee43542f1a4a.jpg: 640x640 2 golfballs, 82.4ms\n",
      "Speed: 1.8ms preprocess, 82.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'golfball'}\n",
       " obb: None\n",
       " orig_img: array([[[201, 171, 144],\n",
       "         [202, 173, 146],\n",
       "         [204, 175, 148],\n",
       "         ...,\n",
       "         [186, 164, 129],\n",
       "         [186, 164, 129],\n",
       "         [184, 162, 127]],\n",
       " \n",
       "        [[206, 176, 151],\n",
       "         [207, 178, 151],\n",
       "         [207, 180, 154],\n",
       "         ...,\n",
       "         [184, 162, 127],\n",
       "         [186, 161, 127],\n",
       "         [185, 163, 128]],\n",
       " \n",
       "        [[211, 183, 159],\n",
       "         [211, 186, 160],\n",
       "         [212, 186, 162],\n",
       "         ...,\n",
       "         [183, 159, 123],\n",
       "         [187, 161, 125],\n",
       "         [188, 164, 128]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 33,  47,  45],\n",
       "         [ 34,  48,  46],\n",
       "         [ 37,  51,  49],\n",
       "         ...,\n",
       "         [ 22,  79,  58],\n",
       "         [ 21,  78,  57],\n",
       "         [ 21,  78,  57]],\n",
       " \n",
       "        [[ 29,  43,  41],\n",
       "         [ 29,  43,  41],\n",
       "         [ 29,  43,  41],\n",
       "         ...,\n",
       "         [ 24,  81,  60],\n",
       "         [ 23,  80,  59],\n",
       "         [ 22,  79,  58]],\n",
       " \n",
       "        [[ 42,  56,  54],\n",
       "         [ 39,  53,  51],\n",
       "         [ 34,  48,  46],\n",
       "         ...,\n",
       "         [ 25,  82,  61],\n",
       "         [ 24,  81,  60],\n",
       "         [ 22,  79,  58]]], dtype=uint8)\n",
       " orig_shape: (640, 640)\n",
       " path: '/root/YOLO_GOLF/GolfBallDetector-10/test/images/6ced8d90b264f0ac_jpg.rf.d6f2a323158e8412ae30ee43542f1a4a.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/yolov8n_golf_ball_100epoch_10patience2'\n",
       " speed: {'preprocess': 1.7659664154052734, 'inference': 82.41558074951172, 'postprocess': 0.9365081787109375}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지에 대한 예측 수행\n",
    "results = model.predict('/root/YOLO_GOLF/GolfBallDetector-10/test/images/6ced8d90b264f0ac_jpg.rf.d6f2a323158e8412ae30ee43542f1a4a.jpg', conf=0.25)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
